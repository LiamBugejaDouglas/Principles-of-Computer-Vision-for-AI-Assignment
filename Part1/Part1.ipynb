{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a006d9d4",
   "metadata": {},
   "source": [
    "# ARI2129 Assignment - Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43d537e",
   "metadata": {},
   "source": [
    "Importing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cb7987b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef3eb50",
   "metadata": {},
   "source": [
    "### Stage 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae7e307",
   "metadata": {},
   "source": [
    "This stage requires to blend an image from an object, taken from one image and adding it onto another image.\n",
    "\n",
    "img_s1, contains an image with a single object, shampoo bottle.\n",
    "\n",
    "img_s2, contains an image with two objetcs, shampoo bottle and deodarant.\n",
    "\n",
    "img_mask, contains mask of shampoo bottle.\n",
    "\n",
    "bg_book, backgorund with a book.\n",
    "\n",
    "bg_per, background with computer peripherals.\n",
    "\n",
    "bg_statue, background with religious statue.\n",
    "\n",
    "bg_vase, background with vase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f7245fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Images\n",
    "img_s1 = cv.imread(\"images/Part1/objects/single_1_obj.jpeg\")\n",
    "img_s2 = cv.imread(\"images/Part1/objects/mult_2_obj.jpeg\")\n",
    "#Mask\n",
    "img_mask = cv.imread(\"images/Part1/mask/wash_mask.png\")\n",
    "#Background\n",
    "bg_book = cv.imread(\"images/Part1/backgrounds/book.jpeg\")\n",
    "bg_per = cv.imread(\"images/Part1/backgrounds/peripherals.jpeg\")\n",
    "bg_statue = cv.imread(\"images/Part1/backgrounds/statue.jpeg\")\n",
    "bg_vase = cv.imread(\"images/Part1/backgrounds/vase.jpeg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4833d9d",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57f52a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.imshow(\"test\", img_s1)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23453841",
   "metadata": {},
   "source": [
    "Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6eb59d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractObject(s2, objectMask):\n",
    "    \n",
    "    img_extract = s2*objectMask\n",
    "    #Invert colours, since it is multiplied with white pixels of mask\n",
    "    img_extract= cv.bitwise_not(img_extract)\n",
    "    \n",
    "    return img_extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63c69f8",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bf86e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractedObject = ExtractObject(img_s2, img_mask)\n",
    "cv.imshow(\"test\", extractedObject)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb706030",
   "metadata": {},
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ac6b7bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApplyFilter(extractedObject, filterIndex):\n",
    "\n",
    "    #Apply no filter\n",
    "    if(filterIndex==0):\n",
    "    \n",
    "        filteredExObject = extractedObject\n",
    "    \n",
    "    #Apply Opening filter\n",
    "    elif(filterIndex==1):\n",
    "         \n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        \n",
    "        filteredExObject = cv.morphologyEx(extractedObject, cv.MORPH_OPEN, kernel)\n",
    "    \n",
    "    #Apply Gaussian blur\n",
    "    elif(filterIndex==2):\n",
    "        \n",
    "        kernel = np.ones((5,5),np.float32)/40\n",
    "        filteredExObject = cv.filter2D(extractedObject,-1,kernel)\n",
    "        \n",
    "    #Apply Histogram Equalisation filter\n",
    "    elif(filterIndex==3):\n",
    "        \n",
    "        img_yuv = cv.cvtColor(extractedObject, cv.COLOR_BGR2YUV)\n",
    "        img_yuv[:,:,0] = cv.equalizeHist(img_yuv[:,:,0])\n",
    "        filteredExObject = cv.cvtColor(img_yuv, cv.COLOR_YUV2BGR)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print(\"Out of range, please use between 1-3.\")\n",
    "        \n",
    "    return filteredExObject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc485fd1",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9f345d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterImage = ApplyFilter(extractedObject, 1)\n",
    "\n",
    "cv.imshow(\"test1\", filterImage)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb4ee4e",
   "metadata": {},
   "source": [
    "Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5b02693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ObjectBlender(s1, filteredExObject):\n",
    "    \n",
    "    alpha = 0.70\n",
    "    beta = 1.0 - alpha\n",
    "    blendingResult = cv.addWeighted(s1, alpha, filteredExObject, beta, -60)\n",
    "    \n",
    "    return blendingResult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da3e8d2",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dee15d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "blendingResult = ObjectBlender(img_s1, filterImage)\n",
    "cv.imshow('Blended', blendingResult)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18c04c3",
   "metadata": {},
   "source": [
    "Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7f56a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompareResult(blendingResult, s2, metric):\n",
    "    \n",
    "    #Mean Squared Error\n",
    "    if(metric==1):\n",
    "        \n",
    "        error = np.sum((blendingResult.astype(\"float\") - s2.astype(\"float\"))** 2)\n",
    "        error /= float(blendingResult.shape[0] * blendingResult.shape[1])\n",
    "    \n",
    "    #Sum of Squared Distance Error\n",
    "    elif(metric==2):\n",
    "        \n",
    "         error = np.sum((blendingResult-s2)**2)\n",
    "    else:\n",
    "        \n",
    "        print(\"Out of range, please use between 1-2.\")\n",
    "        \n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2a59b6",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "54347bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835.7566786024306\n",
      "144981515\n"
     ]
    }
   ],
   "source": [
    "print(CompareResult(blendingResult, img_s2, 1))\n",
    "print(CompareResult(blendingResult, img_s2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ba01f7",
   "metadata": {},
   "source": [
    "Now we will blend the object in the image using all the different types of filters (no filter,Opening filter,Gaussian blur,Histogram Equalisation) and comapre the originale image with ours using mean squared error and sum of squared distance error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8de74a",
   "metadata": {},
   "source": [
    "Extracting object with its mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ecbd49b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractedObject = ExtractObject(img_s2, img_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84431cc1",
   "metadata": {},
   "source": [
    "Applying filter to extracted object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "421f76d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterImage0 = ApplyFilter(extractedObject, 0)\n",
    "filterImage1 = ApplyFilter(extractedObject, 1)\n",
    "filterImage2 = ApplyFilter(extractedObject, 2)\n",
    "filterImage3 = ApplyFilter(extractedObject, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0049872",
   "metadata": {},
   "source": [
    "Blending the object into the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "af29be04",
   "metadata": {},
   "outputs": [],
   "source": [
    "blending0 = ObjectBlender(img_s1, filterImage0)\n",
    "blending1 = ObjectBlender(img_s1, filterImage1)\n",
    "blending2 = ObjectBlender(img_s1, filterImage2)\n",
    "blending3 = ObjectBlender(img_s1, filterImage3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dc8d78",
   "metadata": {},
   "source": [
    "Calculating the error value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ab8f7abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Filter\n",
      "\n",
      "Mean Squared Error: 938.0311490885416\n",
      "Sum of Squared Distance Error: 144692003\n",
      "---------------------------\n",
      "Opening filter\n",
      "\n",
      "Mean Squared Error: 946.1434233940972\n",
      "Sum of Squared Distance Error: 144695891\n",
      "---------------------------\n",
      "Gaussian blur\n",
      "\n",
      "Mean Squared Error: 3498.710486111111\n",
      "Sum of Squared Distance Error: 319639232\n",
      "---------------------------\n",
      "Histogram Equalisation filter\n",
      "\n",
      "Mean Squared Error: 1295.0648752170139\n",
      "Sum of Squared Distance Error: 144928653\n"
     ]
    }
   ],
   "source": [
    "print(\"No Filter\\n\")\n",
    "print(\"Mean Squared Error:\", CompareResult(blending0 , img_s2, 1))\n",
    "print(\"Sum of Squared Distance Error:\", CompareResult(blending0 , img_s2, 2))\n",
    "print('---------------------------')\n",
    "print(\"Opening filter\\n\")\n",
    "print(\"Mean Squared Error:\", CompareResult(blending1 , img_s2, 1))\n",
    "print(\"Sum of Squared Distance Error:\", CompareResult(blending1 , img_s2, 2))\n",
    "print('---------------------------')\n",
    "print(\"Gaussian blur\\n\")\n",
    "print(\"Mean Squared Error:\", CompareResult(blending2 , img_s2, 1))\n",
    "print(\"Sum of Squared Distance Error:\", CompareResult(blending2 , img_s2, 2))\n",
    "print('---------------------------')\n",
    "print(\"Histogram Equalisation filter\\n\")\n",
    "print(\"Mean Squared Error:\", CompareResult(blending3 , img_s2, 1))\n",
    "print(\"Sum of Squared Distance Error:\", CompareResult(blending3 , img_s2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39109e4d",
   "metadata": {},
   "source": [
    "### Stage 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af14942e",
   "metadata": {},
   "source": [
    "This stage requires removing the green screen from the image and replacing it with 4 different backgrounds from the COTS dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b750f19",
   "metadata": {},
   "source": [
    "Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e38351c",
   "metadata": {},
   "source": [
    "Testing values for upper and lower bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d7ab6ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = np.array([0, 25, 0])\n",
    "upper_bound = np.array([100, 120, 100])\n",
    "    \n",
    "mask = cv.inRange(img_s1,lower_bound, upper_bound)\n",
    "\n",
    "cv.imshow('mask', mask)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4724c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveGreen(img):\n",
    "    \n",
    "    #Defining upper and lower bound of green colour\n",
    "    lower_bound = np.array([0, 25, 0])\n",
    "    upper_bound = np.array([100, 120, 100])\n",
    "    \n",
    "    mask = cv.inRange(img_s1,lower_bound, upper_bound)\n",
    "    \n",
    "    imgNoBg = np.copy(img)\n",
    "    imgNoBg[mask != 0] = [0, 0, 0]\n",
    "    \n",
    "    cv.imshow('imgNoBg', imgNoBg)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "    return mask, imgNoBg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700cd13d",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e4ac0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgNoBg=RemoveGreen(img_s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6313bf43",
   "metadata": {},
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "89d6713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NewBackground(imgNoBg, newBackGround):\n",
    "    \n",
    "    mask, image = RemoveGreen(imgNoBg)\n",
    "    \n",
    "    crop_background = cv.resize(newBackGround,(imgNoBg.shape[1], imgNoBg.shape[0]))\n",
    "    \n",
    "    crop_background[mask == 0] = [0, 0, 0]\n",
    "    \n",
    "    back = np.array(image + crop_background)\n",
    "    \n",
    "    cv.imshow('f', back)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "    return back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc277bab",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "85aa7602",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = NewBackground(img_s1, bg_per)\n",
    "cv.imshow('final', final)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7ce1d4",
   "metadata": {},
   "source": [
    "Adding the shampoo bottle to four different backgrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e9cc610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgbg1=NewBackground(img_s1, bg_book)\n",
    "imgbg2=NewBackground(img_s1, bg_per)\n",
    "imgbg3=NewBackground(img_s1, bg_statue)\n",
    "imgbg4=NewBackground(img_s1, bg_vase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d3438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
